# LLM Prompt Reference

> **Note:** This is reference documentation. The actual prompt is generated by
> `build_llm_prompt_content()` in `cargo-cola/src/main.rs`. If this doc and the code
> diverge, the code is authoritative.

## Overview

`cargo-cola` generates `out/cola/llm-prompt.md` - a structured prompt that guides LLMs through security finding analysis. The prompt helps produce reports with prioritized findings and code fixes.

## Generated Structure

The prompt contains these sections in order:

### 1. Header & Scan Configuration
- Project name, analysis date, tool version, finding count
- Table of CLI flags used with values and sources (user vs default)
- Save instructions for the generated report

### 2. Your Role
Establishes the LLM as a senior security engineer producing a report for:
- Security team (technical details and remediation code)
- Engineering leads (priority and effort estimates)
- Leadership (executive summary and risk posture)

### 3. Step 0: Source Verification (MANDATORY)
**Critical requirement** that the LLM must read actual source files before analyzing any finding.

#### Verification Checklist
| Step | Action | If Cannot Complete |
|------|--------|-------------------|
| Read the file | Fetch actual source at reported lines | Mark as UNVERIFIED |
| Confirm the pattern | Ensure vulnerable construct exists | Dismiss as false positive |
| Check context | Read 20-50 surrounding lines for guards | Note mitigations found |
| Trace call chain | Verify entry point reaches this code | Downgrade reachability |

#### NEVER Do This
- ‚ùå Synthesize or guess what code looks like
- ‚ùå Copy code snippets from tool output without verification
- ‚ùå Write `Vulnerable Code` sections without reading the actual file
- ‚ùå Invent variable names, function signatures, or code patterns

### 4. Step 0.5: Guard Detection (CRITICAL for Reducing False Positives)
**New in v1.0.1** - Guidance on identifying guards that may make findings false positives.

#### What is a Guard?
A guard is any code that validates, bounds, or sanitizes data between a taint source and sink:

| Guard Type | Examples | Effect |
|------------|----------|--------|
| Bounds Check | `if len > MAX { return Err(...) }`, `min()`, `clamp()` | Limits numeric values |
| Validation | `validate_input()`, `is_valid()`, regex checks | Rejects invalid input |
| Sanitization | `escape()`, `sanitize()`, `quote()` | Transforms dangerous chars |
| Type Constraint | Schema validation, column limits, enum parsing | Structural bounds |
| Allowlist | `if !ALLOWED.contains(&x) { return Err(...) }` | Rejects unexpected values |

#### Where to Look for Guards
1. Between source and sink (entire call chain)
2. In constants (`MAX_*`, `LIMIT_*`, `*_LIMIT`)
3. In type definitions (schema validation, enum parsing)
4. In callers (validation before calling reported function)
5. In configuration (framework-level limits)

#### Rule-Specific Guard Patterns
Dynamically generated table based on finding types in the scan. Maps rule IDs to:
- Common guard patterns to search for
- False positive criteria

#### Per-Finding Guard Hints
Each finding includes:
```
**üîç Guard Check:** [What to check for this rule type]
- Search for: `pattern1`, `pattern2`, ...
- **False positive if:** [Conditions that make this a false positive]
```

### 5. Step 1: Aggressive Pruning
Mandatory false positive elimination before analysis:

| Criterion | How to Identify |
|-----------|-----------------|
| Test Code | Path contains `/tests/`, `_test.rs`, `#[test]`, `#[cfg(test)]` |
| Example Code | Path contains `/examples/`, `/demo/`, `/sample/` |
| Benchmark Code | Path contains `/benches/`, `_bench.rs` |
| Build Scripts | File is `build.rs` (unless executing external commands) |
| Compile-time Constants | Value is string literal, `const`, `static` with no runtime input |
| Dead Code | Function never called, behind disabled `#[cfg(feature = "...")]` |
| Documented Unsafe | Has `// SAFETY:` comment explaining why it's safe |

#### Lower Priority (Keep but Deprioritize)
Move to Low/P3 if:
- Requires authenticated access AND has rate limiting
- Impact limited to self-DoS
- Defense-in-depth issue where primary controls exist

### 6. Step 2: Reachability Analysis

| Reachability | Definition | Severity Impact |
|--------------|------------|-----------------|
| EXPOSED | Direct path from untrusted input (HTTP params, CLI args, stdin) | Full severity |
| INDIRECT | Reachable via call chain, may have intermediate processing | -1 if sanitized |
| AUTHENTICATED | Behind authentication/authorization checks | -1 level |
| INTERNAL | Only callable from trusted internal code | -2 levels (min: Low) |
| CONFIG-DRIVEN | Input comes from config files, env vars at startup | Context-dependent |

#### ‚ö†Ô∏è MANDATORY: Authentication Verification Checklist

Before classifying ANY finding as AUTHENTICATED, the analyst MUST verify:

| Check | How to Verify | If Uncertain |
|-------|---------------|--------------|
| Auth middleware exists | Search for `auth`, `authenticate`, `bearer`, `token` in handler chain | Assume EXPOSED |
| Auth is mandatory | Check for `--without-auth`, `DISABLE_AUTH` flags/env vars | Assume EXPOSED |
| Endpoint is protected | Verify endpoint NOT in auth bypass list | Assume EXPOSED |
| Auth cannot be bypassed | Check for debug modes, feature flags that disable auth | Note as CONFIG-DEPENDENT |

If auth can be disabled via config, state BOTH scenarios and use worst-case for severity.

### 7. Step 3: Impact Classification

| Impact Type | Code | Typical Severity |
|-------------|------|------------------|
| Remote Code Execution | RCE | Critical |
| Authentication Bypass | AUTH | Critical |
| Memory Corruption | MEM | Critical |
| SQL/Command Injection | INJ | Critical-High |
| Privilege Escalation | PRIV | High |
| Sensitive Data Exposure | DATA | High |
| Path Traversal | PATH | High-Medium |
| SSRF | SSRF | High-Medium |
| Denial of Service | DOS | Medium |
| Information Disclosure | INFO | Low |

### 8. Step 4: Contextual Severity Rating

```
Final Severity = Base Severity + Reachability Modifier + Context Modifier
```

#### Base Severity (from Impact Type)
Critical ‚Üí High ‚Üí Medium ‚Üí Low

#### Reachability Modifier
- EXPOSED: No change
- INDIRECT: -1 if sanitized
- AUTHENTICATED: -1
- INTERNAL: -2

#### Context Modifiers
- Rate limited: -1 for DoS
- Requires local access: -1
- Already logged/monitored: Note for response

### 9. Step 5: Remediation with Code

Each true positive requires:
- Vulnerable code snippet (verified from source)
- Fixed code snippet (compilable Rust)
- Recommended libraries
- Effort estimate (hours/days)
- Breaking change assessment

#### Remediation Quality Checklist
- Code compiles and follows Rust idioms
- Uses standard library or well-maintained crates
- Includes error handling
- Documents security properties

### 10. Required Output Format

```markdown
# Security Assessment Report: {PROJECT}

## Executive Summary
- Risk Rating: [Critical|High|Medium|Low]
- 2-3 sentence summary
- Findings overview (X Critical, Y High, Z Medium, W Low)

## Critical & High Severity Findings
[Detailed analysis with verified code, attack paths, and fixes]

## Medium Severity Findings
[Analysis with remediation]

## Low Severity Findings
[Summary table]

## Remediation Roadmap
| Priority | Finding | Effort | Target |
|----------|---------|--------|--------|
| P0 | ... | ... | Immediate |
| P1 | ... | ... | Sprint |
| P2 | ... | ... | Quarter |

## Appendix A: False Positives Dismissed
[Evidence-backed dismissals with guard citations]

## Appendix B: Methodology
```

### 11. Findings to Analyze

Findings are presented with:
- Rule ID and severity
- Function and file location
- Context hints (‚ö†Ô∏è Test code, ‚ö†Ô∏è Example code, etc.)
- Code evidence (up to 8 lines of MIR)
- **üîç Guard Check** hints (rule-specific patterns to verify)

Limited to 100 findings maximum to stay within context limits.

### 12. Step 6: Output Verification

Before delivering the report:
- Re-read draft and highlight every code/file reference
- Confirm each path + line exists in Findings table
- Verify quoted snippets match Evidence blocks exactly
- Ensure exploitability statements agree with reachability table

### 13. Final Checklist

- [ ] **CRITICAL: Every code snippet read from actual source files, NOT synthesized**
- [ ] **CRITICAL: Line numbers verified against source**
- [ ] **CRITICAL: Guard patterns searched for each finding (Step 0.5)**
- [ ] All test/example/benchmark code dismissed with evidence
- [ ] Each true positive has reachability classification
- [ ] **CRITICAL: Each AUTHENTICATED claim has evidence**
- [ ] **CRITICAL: Auth bypass flags documented if they exist**
- [ ] Each true positive has impact type
- [ ] Severity reflects reachability, not just base CVSS
- [ ] Remediation includes compilable code fixes
- [ ] Executive summary is 2-3 sentences max
- [ ] Roadmap has clear priorities and effort estimates

## Usage

```bash
cargo-cola --crate-path ./project
# Output: out/cola/llm-prompt.md
```

Copy the contents of `llm-prompt.md` into your AI assistant (Copilot, Claude, ChatGPT) to generate the security report.

## Automated LLM Analysis

```bash
cargo-cola --crate-path ./project \
  --llm-endpoint https://api.openai.com/v1/chat/completions \
  --llm-api-key $OPENAI_API_KEY \
  --llm-report out/cola/security-report.md
```

## Customization

To modify the prompt structure, edit `build_llm_prompt_content()` in [cargo-cola/src/main.rs](../../cargo-cola/src/main.rs).

Guard pattern hints are defined in `get_guard_hints_for_rule()` in the same file.
